from typing import List, Optional, Any, Dict
from sqlalchemy import select, update, delete, text, func, or_
from sqlalchemy.orm import Session, joinedload
from sqlalchemy.exc import SQLAlchemyError
from pathlib import Path
import pandas as pd
import os

from app.models import TestRecord, TestStatus
from app.models.dataset import Dataset
from app.core.database import SessionLocal
from app.schemas.dataset_schema import DatasetRead
from app.schemas.test_record_schema import TestRecordRead, TestRecordStatus
from app.utils.pressure_test_util import (
    dify_get_account_id,
    dify_api_url_2_account_profile_url,
    download_from_tos
)
from loguru import logger


class TestRecordCRUD:
    # ---------------------- åˆ›å»º ----------------------

    @staticmethod
    def create(
        session: Session,
        *,
        filename: str,
        dify_api_url: str,
        dify_bearer_token: str,
        dify_test_agent_id: str,
        dify_username: str,
        dify_account_id: str,
        task_name: str,
        judge_prompt: str,
        agent_type: str,
        agent_name: str,
        status: TestStatus = TestStatus.INIT,
        duration: Optional[int] = None,
        result: Optional[str] = None,
        concurrency: int = 1,
        dify_api_key: Optional[str] = None,
        judge_model: Optional[str] = None,
        judge_model_provider_name: Optional[str] = None,
        dataset_uuid: Optional[str] = None,  # âœ… æ–°å¢ž
        dataset_file_md5: Optional[str] = None,
        dataset_tos_key: Optional[str] = None,
        dataset_tos_url: Optional[str] = None,
        is_deleted: bool = False,
    ) -> TestRecord:
        """åˆ›å»ºæµ‹è¯•è®°å½•"""
        record = TestRecord(
            filename=filename,
            status=status,
            agent_type=agent_type,
            agent_name=agent_name,
            task_name=task_name,
            duration=duration,
            result=result,
            concurrency=concurrency,
            dify_account_id=dify_account_id,
            dify_api_url=dify_api_url,
            dify_bearer_token=dify_bearer_token,
            dify_test_agent_id=dify_test_agent_id,
            dify_api_key=dify_api_key,
            dify_username=dify_username,
            judge_prompt=judge_prompt,
            judge_model=judge_model,
            judge_model_provider_name=judge_model_provider_name,
            dataset_uuid=dataset_uuid,  # âœ… æ–°å¤–é”®
            dataset_file_md5=dataset_file_md5,
            dataset_tos_key=dataset_tos_key,
            dataset_tos_url=dataset_tos_url,
            is_deleted=is_deleted,
        )

        try:
            session.add(record)
            session.commit()
            session.refresh(record)
            logger.info(f"âœ… åˆ›å»ºæµ‹è¯•è®°å½•æˆåŠŸ uuid={record.uuid}, dataset_uuid={dataset_uuid}")
        except SQLAlchemyError as e:
            session.rollback()
            logger.error(f"âŒ åˆ›å»ºæµ‹è¯•è®°å½•å¤±è´¥: {e}")
            raise e

        return record

    # ---------------------- æŸ¥è¯¢ ----------------------

    @staticmethod
    def get_by_uuid(session: Session, uuid_str: str) -> Optional[TestRecord]:
        stmt = (
            select(TestRecord)
            .options(joinedload(TestRecord.dataset))  # âœ… è‡ªåŠ¨å…³è” Dataset
            .where(TestRecord.uuid == uuid_str, TestRecord.is_deleted.is_(False))
        )
        return session.scalars(stmt).first()

    @staticmethod
    def get_by_agent_id(session: Session, agent_id: str) -> Optional[TestRecord]:
        stmt = (
            select(TestRecord)
            .options(joinedload(TestRecord.dataset))
            .where(TestRecord.dify_test_agent_id == agent_id, TestRecord.is_deleted.is_(False))
        )
        return session.scalars(stmt).first()

    @staticmethod
    def list_all(session: Session, limit: int = 100, offset: int = 0) -> List[TestRecord]:
        stmt = (
            select(TestRecord)
            .options(joinedload(TestRecord.dataset))
            .where(TestRecord.is_deleted.is_(False))
            .order_by(TestRecord.created_at.desc())
            .offset(offset)
            .limit(limit)
        )
        return list(session.scalars(stmt).all())

    # ---------------------- æ›´æ–° ----------------------

    @staticmethod
    def update_by_uuid(session: Session, uuid_str: str, **kwargs: Any) -> Optional[TestRecord]:
        """æ ¹æ® uuid æ›´æ–°å­—æ®µï¼ˆåªæ›´æ–°éž None å€¼ï¼‰"""
        update_data: Dict[str, Any] = {k: v for k, v in kwargs.items() if v is not None}
        if not update_data:
            return TestRecordCRUD.get_by_uuid(session, uuid_str)

        stmt = (
            update(TestRecord)
            .where(TestRecord.uuid == uuid_str)
            .values(**update_data)
            .execution_options(synchronize_session="fetch")
        )

        try:
            session.execute(stmt)
            session.commit()
            logger.info(f"ðŸ› ï¸ æ›´æ–°æµ‹è¯•è®°å½• {uuid_str} å­—æ®µ: {list(update_data.keys())}")
        except SQLAlchemyError as e:
            session.rollback()
            logger.error(f"âŒ æ›´æ–°æµ‹è¯•è®°å½•å¤±è´¥: {e}")
            raise e

        return TestRecordCRUD.get_by_uuid(session, uuid_str)

    # ---------------------- åˆ é™¤/æ¢å¤ ----------------------

    @staticmethod
    def delete_by_uuid(session: Session, uuid_str: str) -> bool:
        """è½¯åˆ é™¤"""
        stmt = (
            update(TestRecord)
            .where(TestRecord.uuid == uuid_str)
            .values(is_deleted=True)
            .execution_options(synchronize_session="fetch")
        )
        try:
            result = session.execute(stmt)
            session.commit()
            logger.info(f"ðŸ—‘ï¸ å·²è½¯åˆ é™¤æµ‹è¯•è®°å½•: {uuid_str}")
        except SQLAlchemyError as e:
            session.rollback()
            logger.error(f"âŒ åˆ é™¤æµ‹è¯•è®°å½•å¤±è´¥: {e}")
            raise e
        return result.rowcount > 0

    @staticmethod
    def restore_by_uuid(session: Session, uuid_str: str) -> bool:
        """æ¢å¤è½¯åˆ é™¤"""
        stmt = (
            update(TestRecord)
            .where(TestRecord.uuid == uuid_str)
            .values(is_deleted=False)
            .execution_options(synchronize_session="fetch")
        )
        try:
            result = session.execute(stmt)
            session.commit()
            logger.info(f"â™»ï¸ å·²æ¢å¤æµ‹è¯•è®°å½•: {uuid_str}")
        except SQLAlchemyError as e:
            session.rollback()
            raise e
        return result.rowcount > 0

    # ---------------------- åˆ†é¡µæŸ¥è¯¢ ----------------------

    @staticmethod
    def get_all_records_by_agent_id(input_agent_id: str, page: int, page_size: int):
        with SessionLocal() as session:
            stmt = (
                select(TestRecord)
                .options(joinedload(TestRecord.dataset))
                .where(
                    TestRecord.dify_test_agent_id == input_agent_id,
                    TestRecord.is_deleted.is_(False),
                )
                .offset((page - 1) * page_size)
                .limit(page_size)
            )
            records = session.scalars(stmt).all()

            total_stmt = select(func.count()).select_from(TestRecord).where(
                TestRecord.dify_test_agent_id == input_agent_id,
                TestRecord.is_deleted.is_(False),
            )
            total = session.scalar(total_stmt)

            return {
                "page": page,
                "page_size": page_size,
                "total": total,
                "records": [TestRecordRead.model_validate(r) for r in records],
            }

    # ---------------------- æ•°æ®é›†é¢„è§ˆ ----------------------

    @staticmethod
    def get_dataset_first_three_lines(input_uuid: str):
        """
        æ ¹æ®æµ‹è¯•è®°å½• UUID èŽ·å–å…¶å…³è”æ•°æ®é›†çš„å‰ 3 è¡Œå†…å®¹ã€‚
        è‡ªåŠ¨ä»Ž TOS ä¸‹è½½æ–‡ä»¶é¢„è§ˆã€‚
        """
        with SessionLocal() as session:
            # âœ… æŸ¥è¯¢ TestRecord
            record = session.query(TestRecord).filter(TestRecord.uuid == input_uuid).first()
            if not record:
                raise ValueError("Record not found or deleted.")

            # âœ… ä¼˜å…ˆä½¿ç”¨ Dataset å¤–é”®å…³è”
            dataset = record.dataset
            if not dataset:
                raise ValueError("No dataset linked to this test record.")

            object_key = dataset.tos_key
            suffix = dataset.file_suffix or ".csv"
            tmp_dir = Path("uploads/previews")
            tmp_dir.mkdir(parents=True, exist_ok=True)
            tmp_path = tmp_dir / f"preview_{dataset.file_md5}{suffix}"

            try:
                # âœ… ä»Žç«å±± TOS ä¸‹è½½æ–‡ä»¶
                download_from_tos(object_key, str(tmp_path))
                logger.info(f"âœ… ä»Ž TOS ä¸‹è½½å®Œæˆ: {tmp_path}")

                # âœ… æ ¹æ®æ–‡ä»¶ç±»åž‹è¯»å–
                if suffix == ".csv":
                    df = pd.read_csv(tmp_path)
                elif suffix in [".xls", ".xlsx"]:
                    df = pd.read_excel(tmp_path, engine="openpyxl")
                else:
                    raise ValueError(f"Unsupported file type: {suffix}")

                preview = df.head(3).to_dict(orient="records")
                logger.info(f"âœ… é¢„è§ˆæˆåŠŸï¼Œå…± {len(df)} è¡Œï¼Œå–å‰ 3 è¡Œå±•ç¤º")

                return preview

            except Exception as e:
                logger.error(f"âŒ æ–‡ä»¶é¢„è§ˆå¤±è´¥: {e}")
                raise RuntimeError(f"Failed to preview dataset: {e}")

            finally:
                # âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                try:
                    if tmp_path.exists():
                        os.remove(tmp_path)
                        logger.info(f"ðŸ§¹ å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {tmp_path}")
                except Exception as e:
                    logger.warning(f"âš ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    # ---------------------- æ¨¡ç³Šæœç´¢ ----------------------

    @staticmethod
    def get_records_by_keyword(key_word: str, page: int, page_size: int):
        with SessionLocal() as session:
            stmt = (
                select(TestRecord)
                .options(joinedload(TestRecord.dataset))
                .where(TestRecord.is_deleted.is_(False))
            )

            if key_word:
                like_pattern = f"%{key_word}%"
                stmt = stmt.where(
                    or_(
                        TestRecord.task_name.ilike(like_pattern),
                        TestRecord.agent_name.ilike(like_pattern),
                    )
                )

            stmt = stmt.order_by(TestRecord.created_at.desc()).offset((page - 1) * page_size).limit(page_size)
            records = session.scalars(stmt).all()

            count_stmt = select(func.count()).select_from(TestRecord).where(TestRecord.is_deleted.is_(False))
            if key_word:
                count_stmt = count_stmt.where(
                    or_(
                        TestRecord.task_name.ilike(like_pattern),
                        TestRecord.agent_name.ilike(like_pattern),
                    )
                )
            total = session.scalar(count_stmt)

            return {
                "page": page,
                "page_size": page_size,
                "total": total,
                "records": [TestRecordRead.model_validate(r) for r in records],
            }

    @staticmethod
    def increment_success_count(uuid_str: str) -> bool:
        """
        âœ… æˆåŠŸæ¬¡æ•° +1
        """
        with SessionLocal() as session:
            try:
                session.execute(
                    text("""
                         UPDATE test_records
                         SET success_count = success_count + 1
                         WHERE uuid = :uuid_str
                           AND is_deleted = 0
                         """),
                    {"uuid_str": uuid_str},
                )
                session.commit()
                logger.debug(f"âœ… æˆåŠŸæ¬¡æ•° +1ï¼Œuuid={uuid_str}")
                return True
            except SQLAlchemyError as e:
                session.rollback()
                logger.error(f"âŒ æˆåŠŸæ¬¡æ•°æ›´æ–°å¤±è´¥: {e}")
                return False

    @staticmethod
    def increment_failure_count(uuid_str: str) -> bool:
        """
        âŒ å¤±è´¥æ¬¡æ•° +1
        """
        with SessionLocal() as session:
            try:
                session.execute(
                    text("""
                         UPDATE test_records
                         SET failure_count = failure_count + 1
                         WHERE uuid = :uuid_str
                           AND is_deleted = 0
                         """),
                    {"uuid_str": uuid_str},
                )
                session.commit()
                logger.debug(f"âš ï¸ å¤±è´¥æ¬¡æ•° +1ï¼Œuuid={uuid_str}")
                return True
            except SQLAlchemyError as e:
                session.rollback()
                logger.error(f"âŒ å¤±è´¥æ¬¡æ•°æ›´æ–°å¤±è´¥: {e}")
                return False

    @staticmethod
    def get_records_by_uuid_and_bearer_token(agent_id: str, bearer_token: str):
        """
        âœ… æ ¹æ® TestRecord UUID å’Œ Bearer Token èŽ·å–è¯¥ dify_account ä¸‹çš„æ‰€æœ‰æµ‹è¯•è®°å½•
        """
        with SessionLocal() as session:
            # 1ï¸âƒ£ èŽ·å–æŒ‡å®šè®°å½•
            record = session.scalar(
                select(TestRecord).where(
                    TestRecord.dify_test_agent_id == agent_id,
                    TestRecord.is_deleted.is_(False)
                )
            )
            if not record:
                logger.warning(f"âŒ æœªæ‰¾åˆ°agent_idçš„å¯¹åº”è®°å½•: {agent_id}")
                return []

            # 2ï¸âƒ£ èŽ·å– Dify Account ID
            try:
                profile_url = dify_api_url_2_account_profile_url(record.dify_api_url)
                dify_account_id = dify_get_account_id(profile_url, bearer_token)
                logger.info(f"âœ… èŽ·å– dify_account_id æˆåŠŸ: {dify_account_id}")
            except Exception as e:
                logger.error(f"âŒ èŽ·å– dify_account_id å¤±è´¥: {e}")
                return []

            # 3ï¸âƒ£ æŸ¥è¯¢è¯¥è´¦å·ä¸‹æ‰€æœ‰æµ‹è¯•è®°å½•
            stmt = (
                select(TestRecord)
                .where(
                    TestRecord.dify_account_id == dify_account_id,
                    TestRecord.is_deleted.is_(False)
                )
                .order_by(TestRecord.created_at.desc())
            )
            records = session.scalars(stmt).all()

            # 4ï¸âƒ£ è½¬æ¢ä¸º Pydantic æ¨¡åž‹åˆ—è¡¨
            return [TestRecordRead.model_validate(r) for r in records]

    @staticmethod
    def get_by_uuid_include_deleted(session, uuid_str: str, as_dict: bool = False) -> Optional[TestRecord]:
        """
        æ ¹æ® UUID èŽ·å–æµ‹è¯•è®°å½•ï¼ˆåŒ…æ‹¬è½¯åˆ é™¤çš„è®°å½•ï¼‰
        - æ”¯æŒåŠ è½½ Dataset å¤–é”®
        - å¯é€‰è¿”å›ž dict
        """
        try:
            stmt = (
                select(TestRecord)
                .options(joinedload(TestRecord.dataset))
                .where(TestRecord.uuid == uuid_str)
            )
            record = session.scalars(stmt).first()

            if not record:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è®°å½•: uuid={uuid_str}")
                return None

            logger.info(
                f"âœ… æŸ¥è¯¢åˆ°è®°å½• uuid={record.uuid}, is_deleted={record.is_deleted}, "
                f"dataset_uuid={getattr(record.dataset, 'uuid', None)}"
            )

            if as_dict:
                data = record.to_dict(exclude_none=True)
                if record.dataset:
                    data["dataset"] = record.dataset.to_dict(exclude_none=True)
                return data

            return record

        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢è®°å½•å¤±è´¥: uuid={uuid_str}, é”™è¯¯={e}")
            raise

    @staticmethod
    def get_uuid_task_status(uuid: str) -> TestRecordStatus:
        """
        æ ¹æ® UUID èŽ·å–æµ‹è¯•ä»»åŠ¡çŠ¶æ€ï¼ˆåŒ…å« dataset ä¿¡æ¯ï¼‰
        """
        with SessionLocal() as session:
            try:
                stmt = (
                    select(TestRecord)
                    .options(joinedload(TestRecord.dataset))
                    .where(TestRecord.uuid == uuid)
                )
                record = session.scalars(stmt).first()

                if not record:
                    logger.warning(f"âš ï¸ æœªæ‰¾åˆ°æµ‹è¯•ä»»åŠ¡: uuid={uuid}")
                    raise ValueError("Record not found or deleted.")

                # âœ… ç»„è£…ç»“æžœ
                result = {
                    "uuid": record.uuid,
                    "status": record.status,
                    "task_name": record.task_name,
                    "agent_name": record.agent_name,
                    "is_deleted": record.is_deleted,
                }

                # âœ… å¦‚æžœæœ‰å…³è”æ•°æ®é›†ï¼Œåˆ™é™„å¸¦æ•°æ®é›†æ‘˜è¦
                if record.dataset:
                    result["dataset"] = DatasetRead.model_validate(record.dataset)

                logger.info(f"âœ… æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€æˆåŠŸ: uuid={uuid}, status={record.status}")
                return TestRecordStatus(**result)

            except Exception as e:
                logger.error(f"âŒ èŽ·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
                raise

    @staticmethod
    def update_judge_model(input_uuid: str, judge_model_name: str):
        with SessionLocal() as session:
            TestRecordCRUD.update_by_uuid(session, input_uuid, judge_model=judge_model_name)

    @staticmethod
    def get_datasets_by_agent_and_bearer_token(agent_id: str, bearer_token: str, page: int = 1, page_size: int = 10):
        """
        âœ… æ ¹æ® agent_id + bearer_token æŸ¥è¯¢è¯¥è´¦æˆ·ä¸‹çš„æ‰€æœ‰æµ‹è¯•è®°å½•åŠå…¶å¯¹åº”æ•°æ®é›†ï¼ˆåˆ†é¡µï¼‰
        """
        with SessionLocal() as session:
            try:
                # 1ï¸âƒ£ æŸ¥æ‰¾ä¸€æ¡è®°å½•ä»¥èŽ·å– dify_api_url
                record = session.scalar(
                    select(TestRecord).where(
                        TestRecord.dify_test_agent_id == agent_id,
                        TestRecord.is_deleted.is_(False),
                        TestRecord.dataset_uuid.is_not(None)
                    )
                )
                if not record:
                    logger.warning(f"âŒ æœªæ‰¾åˆ°å¯¹åº” agent_id çš„è®°å½•: {agent_id}")
                    return {
                        "page": page,
                        "page_size": page_size,
                        "total": 0,
                        "records": [],
                    }

                # 2ï¸âƒ£ å°† bearer_token è½¬æ¢ä¸º account_id
                try:
                    profile_url = dify_api_url_2_account_profile_url(record.dify_api_url)
                    dify_account_id = dify_get_account_id(profile_url, bearer_token)
                    logger.info(f"âœ… èŽ·å– dify_account_id æˆåŠŸ: {dify_account_id}")
                except Exception as e:
                    logger.error(f"âŒ èŽ·å– dify_account_id å¤±è´¥: {e}")
                    return {
                        "page": page,
                        "page_size": page_size,
                        "total": 0,
                        "records": [],
                    }

                # 3ï¸âƒ£ è®¡ç®—æ€»æ•°
                total_stmt = (
                    select(func.count())
                    .select_from(TestRecord)
                    .where(
                        TestRecord.dify_account_id == dify_account_id,
                        TestRecord.dify_test_agent_id == agent_id,
                        TestRecord.is_deleted.is_(False),
                        TestRecord.dataset_uuid.is_not(None)
                    )
                )
                total = session.scalar(total_stmt)

                # 4ï¸âƒ£ åˆ†é¡µæŸ¥è¯¢è®°å½•
                stmt = (
                    select(TestRecord)
                    .options(joinedload(TestRecord.dataset))
                    .where(
                        TestRecord.dify_account_id == dify_account_id,
                        TestRecord.dify_test_agent_id == agent_id,
                        TestRecord.is_deleted.is_(False),
                        TestRecord.dataset_uuid.is_not(None)
                    )
                    .order_by(TestRecord.created_at.desc())
                    .offset((page - 1) * page_size)
                    .limit(page_size)
                )
                records = session.scalars(stmt).all()

                # 5ï¸âƒ£ ç»„è£…è¿”å›žç»“æžœ
                result_items = []
                for rec in records:
                    try:
                        dataset_obj = (
                            DatasetRead.model_validate(rec.dataset)
                            if rec.dataset else None
                        )
                        record_obj = TestRecordRead.model_validate(rec)
                        result_items.append({
                            "record": record_obj,
                            "dataset": dataset_obj
                        })
                    except Exception as e:
                        logger.warning(f"âš ï¸ è½¬æ¢è®°å½•å¤±è´¥: uuid={rec.uuid}, é”™è¯¯={e}")

                logger.info(f"âœ… åˆ†é¡µæŸ¥è¯¢æˆåŠŸ: page={page}, page_size={page_size}, total={total}")
                return {
                    "page": page,
                    "page_size": page_size,
                    "total": total,
                    "records": result_items,
                }

            except Exception as e:
                logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
                raise

    @staticmethod
    def detach_dataset(uuid_str: str) -> bool:
        """å°† TestRecord çš„ dataset è§£ç»‘ï¼ˆdataset_uuid ç½®ç©ºï¼‰"""
        with SessionLocal() as db:
            record = db.query(TestRecord).filter(
                TestRecord.uuid == uuid_str,
                TestRecord.is_deleted == False
            ).first()

            if not record:
                return False

            # æ¸…ç©ºå¤–é”®å¼•ç”¨
            record.dataset_uuid = None
            db.commit()
            return True