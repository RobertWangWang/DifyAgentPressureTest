import pandas as pd
import io
from pathlib import Path
from typing import List
from starlette.datastructures import UploadFile as StarletteUploadFile
from fastapi import APIRouter, Depends, HTTPException, Request, UploadFile, status, Query, Body, BackgroundTasks
from starlette.responses import JSONResponse, StreamingResponse
from fastapi.concurrency import run_in_threadpool
from pydantic import ValidationError
from sqlalchemy.orm import Session
import asyncio
import hashlib

from app.crud.test_record_crud import TestRecordCRUD
from app.crud.dataset_crud import DatasetCRUD
from app.models.dataset import Dataset
from app.models.provider_model import ProviderModel
from app.models.test_record import TestRecord, TestStatus, AgentType
from app.schemas.test_record_schema import (
    TestRecordCreate,
    TestRecordRead,
    TestRecordUpdate,
    PaginatedTestRecordResponse,
    TestRecordsByUUIDAndBearerToken,
    TestRecordStatus,
    AgentParameterRequest,
)
from app.schemas.dataset_schema import DatasetCreate, DatasetRead
from app.core.config import settings
from app.core.database import SessionLocal
from app.services.test_record_services import (
    test_chatflow_non_stream_pressure_wrapper,
    test_workflow_non_stream_pressure_wrapper,
)
from app.services.provider_model_services import llm_connection_test
from app.utils.pressure_test_util import (
    dify_api_url_2_agent_apikey_url,
    dify_api_url_2_agent_api_app_url,
    dify_get_agent_type_and_agent_name,
    create_dify_agent_api_key,
    get_dify_agent_api_key,
    dify_get_account_id,
    dify_api_url_2_account_profile_url,
    get_workflow_parameter_template,
    get_chatflow_parameter_template,
    AgentType,
    upload_to_tos,
)
from loguru import logger

router = APIRouter(prefix="/test_records", tags=["TestChatflowRecords"])


def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


def compute_md5_bytes(data: bytes) -> str:
    """è®¡ç®—æ–‡ä»¶å†…å®¹çš„ MD5"""
    md5 = hashlib.md5()
    md5.update(data)
    return md5.hexdigest()


# ==========================================================
# âœ… ä¸Šä¼ æ•°æ®é›†æ–‡ä»¶ï¼ˆDataset æ‹†è¡¨åï¼‰
# ==========================================================
@router.post("/upload", response_model=DatasetRead, status_code=status.HTTP_201_CREATED)
async def upload_dataset(request: Request, db: Session = Depends(get_db)):
    """
    ä¸Šä¼ æ•°æ®é›†æ–‡ä»¶åˆ°ç«å±± TOSï¼Œè®¡ç®— MD5 å¹¶å†™å…¥ Dataset è¡¨ã€‚
    è‹¥ç›¸åŒ MD5 æ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™ç›´æ¥å¤ç”¨ã€‚
    """
    form = await request.form()
    upload = form.get("file")
    uploaded_by = form.get("uploaded_by", "anonymous")

    if not isinstance(upload, StarletteUploadFile):
        raise HTTPException(status_code=400, detail="å¿…é¡»åŒ…å« file å­—æ®µ")

    # âœ… è¯»å–æ–‡ä»¶å†…å®¹å¹¶è®¡ç®— MD5
    file_bytes = await upload.read()
    suffix = Path(upload.filename).suffix.lower()
    file_md5 = compute_md5_bytes(file_bytes)
    logger.info(f"ğŸ“¦ ä¸Šä¼ æ–‡ä»¶ {upload.filename} çš„ MD5: {file_md5}")

    # âœ… æŸ¥é‡é€»è¾‘
    existing = DatasetCRUD.get_by_md5(db, file_md5)
    if existing:
        logger.info(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¤ç”¨æ•°æ®é›†: {existing.tos_url}")
        return existing

    # âœ… å†™å…¥ä¸´æ—¶æ–‡ä»¶
    upload_dir = Path(settings.FILE_UPLOAD_DIR)
    upload_dir.mkdir(parents=True, exist_ok=True)
    tmp_path = upload_dir / f"{file_md5}{suffix}"
    tmp_path.write_bytes(file_bytes)

    # âœ… ä¸Šä¼ è‡³ TOS
    tos_key = f"datasets/{file_md5}{suffix}"
    try:
        tos_url = await asyncio.to_thread(upload_to_tos, tmp_path, tos_key)
        logger.info(f"âœ… ä¸Šä¼ è‡³ TOS æˆåŠŸ: {tos_url}")
    except Exception as e:
        logger.error(f"âŒ ä¸Šä¼ è‡³ TOS å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"TOS ä¸Šä¼ å¤±è´¥: {e}")
    finally:
        if tmp_path.exists():
            tmp_path.unlink()
            logger.info(f"ğŸ§¹ å·²åˆ é™¤æœ¬åœ°ä¸´æ—¶æ–‡ä»¶: {tmp_path}")

    # âœ… ç”Ÿæˆæ–‡ä»¶é¢„è§ˆ
    preview_rows = []
    try:
        if suffix == ".csv":
            df = pd.read_csv(io.BytesIO(file_bytes))
        elif suffix in [".xls", ".xlsx"]:
            df = pd.read_excel(io.BytesIO(file_bytes))
        preview_rows = df.head(3).to_dict(orient="records")
    except Exception as e:
        logger.warning(f"âš ï¸ é¢„è§ˆæ–‡ä»¶å†…å®¹å¤±è´¥ï¼ˆéå…³é”®æ­¥éª¤ï¼‰{e}")

    # âœ… å†™å…¥ Dataset è¡¨
    dataset = DatasetCreate(
        filename=upload.filename,
        file_md5=file_md5,
        file_suffix=suffix,
        tos_key=tos_key,
        tos_url=tos_url,
        preview_rows=preview_rows,
        uploaded_by=uploaded_by,
    )
    created = DatasetCRUD.create(db, dataset)
    logger.info(f"âœ… æ•°æ®é›†å†™å…¥æˆåŠŸ: uuid={created.uuid}")
    return created


# ==========================================================
# âœ… åˆ›å»ºè¯„æµ‹ä»»åŠ¡ï¼ˆå¼•ç”¨ dataset_uuidï¼‰
# ==========================================================
@router.post("/create_record", response_model=dict, status_code=status.HTTP_201_CREATED)
async def create_record(request: Request, db: Session = Depends(get_db)):
    """
    åˆ›å»ºè¯„æµ‹ä»»åŠ¡ï¼ˆé€šè¿‡ dataset_file_md5 å¼•ç”¨ Datasetï¼‰
    - ä¸è¦æ±‚ dataset_uuid
    - agent_type å’Œ agent_name ç”± Dify è‡ªåŠ¨è¡¥å…¨
    - åŒæ­¥åˆ›å»º Dify API Key å¹¶éªŒè¯ LLM è¿æ¥
    """
    json_data = await request.json()
    try:
        record_payload = TestRecordCreate(**json_data)
    except ValidationError as e:
        raise HTTPException(status_code=422, detail=e.errors())

    file_uuid = json_data.get("dataset_file_uuid")
    if not file_uuid:
        raise HTTPException(status_code=400, detail="å¿…é¡»æä¾› dataset_file_md5")

    # âœ… 1. æŸ¥æ‰¾æ•°æ®é›†
    dataset_info = DatasetCRUD.get_by_uuid(db, file_uuid)
    logger.debug(dataset_info)
    if not dataset_info:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°å¯¹åº”æ•°æ®é›†ï¼Œè¯·å…ˆä¸Šä¼ ")

    # âœ… 2. ç”Ÿæˆ Dify API Key
    try:
        api_key_url = dify_api_url_2_agent_apikey_url(
            record_payload.dify_api_url, record_payload.dify_test_agent_id
        )
        existing_keys = get_dify_agent_api_key(api_key_url, record_payload.dify_bearer_token)
        token_value = (
            existing_keys[0].get("token")
            if existing_keys
            else create_dify_agent_api_key(api_key_url, record_payload.dify_bearer_token).get("token")
        )
        if not token_value:
            raise ValueError("Dify è¿”å›æ— æ•ˆ API Key")
        record_payload.dify_api_key = token_value
        logger.info("âœ… å·²ç”Ÿæˆ Dify API Key")
    except Exception as e:
        logger.error(f"âŒ åˆ›å»º Dify API Key å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»º Dify API Key å¤±è´¥: {e}")

    # âœ… 3. åˆ›å»º TestRecord åŸºç¡€è®°å½•ï¼ˆagent_type/agent_name æš‚ä¸ºç©ºï¼‰
    payload_dict = record_payload.model_dump(exclude={"agent_type", "agent_name"})
    payload_dict['dataset_uuid'] = dataset_info.uuid
    created = TestRecordCRUD.create(
        db,
        filename=dataset_info.filename,
        dataset_tos_key=dataset_info.tos_key,
        dataset_tos_url=dataset_info.tos_url,
        dify_account_id="",  # âœ… å ä½
        agent_type=AgentType.CHATFLOW,  # âœ… å ä½
        agent_name="",  # âœ… å ä½
        **payload_dict,
    )
    logger.info(f"âœ… å·²åˆ›å»ºæµ‹è¯•ä»»åŠ¡è®°å½• uuid={created.uuid}, dataset_uuid={dataset_info.uuid}")

    # âœ… 4. è·å– Agent ç±»å‹ä¸åç§°
    try:
        agent_api_app_url = dify_api_url_2_agent_api_app_url(
            record_payload.dify_api_url, record_payload.dify_test_agent_id
        )
        info = dify_get_agent_type_and_agent_name(agent_api_app_url, record_payload.dify_bearer_token)
        agent_type = info.get("agent_type")
        agent_name = info.get("agent_name")

        if agent_type and agent_name:
            TestRecordCRUD.update_by_uuid(db, created.uuid, agent_type=agent_type, agent_name=agent_name)
            logger.info(f"âœ… å·²æ›´æ–° agent_type={agent_type}, agent_name={agent_name}")
    except Exception as e:
        logger.warning(f"âš ï¸ è·å– Agent ä¿¡æ¯å¤±è´¥ï¼ˆéå…³é”®æ­¥éª¤ï¼‰: {e}")

    # âœ… 5. è·å– Dify Account ID
    try:
        account_profile_url = dify_api_url_2_account_profile_url(record_payload.dify_api_url)
        dify_account_id = dify_get_account_id(account_profile_url, record_payload.dify_bearer_token)
        TestRecordCRUD.update_by_uuid(db, created.uuid, dify_account_id=dify_account_id)
        logger.info(f"âœ… å·²æ›´æ–° Dify Account ID: {dify_account_id}")
    except Exception as e:
        logger.warning(f"âš ï¸ è·å– Dify Account ID å¤±è´¥ï¼ˆéå…³é”®æ­¥éª¤ï¼‰: {e}")

    # âœ… 6. éªŒè¯ LLM å¯ç”¨æ€§
    try:
        judge_model = record_payload.judge_model
        provider = record_payload.judge_model_provider_name
        llm_models = (
            db.query(ProviderModel)
            .filter(ProviderModel.provider_name == provider, ProviderModel.model_name == judge_model)
            .all()
        )
        llm = llm_connection_test(candidate_models=llm_models)
        request.session["llm"] = llm
        logger.info("âœ… LLM æ¨¡å‹è¿æ¥æµ‹è¯•é€šè¿‡")
    except Exception as e:
        logger.warning(f"âš ï¸ LLM æ¨¡å‹è¿æ¥å¤±è´¥ï¼ˆéå…³é”®æ­¥éª¤ï¼‰: {e}")

    # âœ… 7. è¿”å›ç»“æœ
    return JSONResponse(
        content={
            "message": "âœ… è¯„æµ‹ä»»åŠ¡åˆ›å»ºæˆåŠŸ",
            "record_uuid": created.uuid,
            "dataset_file_md5": file_uuid,
            "dataset_tos_url": dataset_info.tos_url,
        }
    )


@router.get("/{uuid_str}", response_model=TestRecordRead)
def get_record(uuid_str: str, db: Session = Depends(get_db)):
    rec = TestRecordCRUD.get_by_uuid(db, uuid_str)
    if rec is None:
        raise HTTPException(status_code=404, detail="Record not found")
    return rec


@router.get("/", response_model=List[TestRecordRead])
def list_records(limit: int = 100, db: Session = Depends(get_db)):
    return TestRecordCRUD.list_all(db, limit=limit)


@router.patch("/{uuid_str}", response_model=TestRecordRead)
def update_record(uuid_str: str, payload: TestRecordUpdate, db: Session = Depends(get_db)):
    existing = TestRecordCRUD.get_by_uuid(db, uuid_str)
    if existing is None:
        raise HTTPException(status_code=404, detail="Record not found")
    updated = TestRecordCRUD.update_by_uuid(db, uuid_str, **payload.dict(exclude_unset=True))
    return updated



@router.delete("/{uuid_str}", response_model=TestRecordRead, status_code=status.HTTP_200_OK)
def delete_record(uuid_str: str, db: Session = Depends(get_db)):
    existing = TestRecordCRUD.get_by_uuid(db, uuid_str)
    if existing is None:
        raise HTTPException(status_code=404, detail="Record not found")

    success = TestRecordCRUD.delete_by_uuid(db, uuid_str)
    if not success:
        raise HTTPException(status_code=500, detail="Delete failed")

    # âœ… å†æŸ¥è¯¢ä¸€æ¬¡ï¼ˆå³ä½¿è¢«æ ‡è®°ä¸ºåˆ é™¤ï¼‰
    deleted_record = TestRecordCRUD.get_by_uuid_include_deleted(db, uuid_str)
    if not deleted_record:
        raise HTTPException(status_code=404, detail="Deleted record not found")

    return TestRecordRead.model_validate(deleted_record)


@router.get(
    "/get_records_by_agent_id/{agent_id}",
    response_model=PaginatedTestRecordResponse,
    status_code=status.HTTP_200_OK
)
def get_records_by_agent_id(
    agent_id: str,
    page: int = Query(1, ge=1, description="é¡µç ï¼Œä»1å¼€å§‹"),
    page_size: int = Query(10, ge=1, le=100, description="æ¯é¡µè¿”å›çš„æ¡ç›®æ•°ï¼Œé»˜è®¤10ï¼Œæœ€å¤§100"),
):
    return TestRecordCRUD.get_all_records_by_agent_id(agent_id, page, page_size)

@router.post("/run_test/{uuid_str}", status_code=status.HTTP_200_OK)
async def run_record(
        request: Request,
        uuid_str: str,
        background_tasks: BackgroundTasks,db: Session = Depends(get_db),
        mode: str = Query(default="all", description="experiment or full mode+"),
):
    existing = await run_in_threadpool(TestRecordCRUD.get_by_uuid, db, uuid_str)
    if existing is None:
        raise HTTPException(status_code=404, detail="Record not found")

    if existing.status == "running":
        return {"error": "æµ‹è¯•ä»»åŠ¡æ­£åœ¨è¿è¡Œä¸­"}
    elif existing.status == "success":
        return existing.result
    elif existing.status == "cancelled":
        return {"error": "æµ‹è¯•ä»»åŠ¡å·²å–æ¶ˆ"}

    if existing.agent_type == "chatflow":
        background_tasks.add_task(test_chatflow_non_stream_pressure_wrapper, existing, request, db, mode)
    elif  existing.agent_type == "workflow":
        background_tasks.add_task(test_workflow_non_stream_pressure_wrapper, existing, request, db, mode)

    return JSONResponse(content={
        "status": "running",
        "message": "æµ‹è¯•å·²åœ¨åå°å¯åŠ¨ âœ…"
    })

@router.get("/get_dataset_first_three_lines/{uuid_str}", status_code=status.HTTP_200_OK)
def get_dataset_first_three_lines(uuid_str: str):

    return TestRecordCRUD.get_dataset_first_three_lines(uuid_str)

@router.post("/get_records_by_uuid_and_bearer_token",status_code=status.HTTP_200_OK,response_model=List[TestRecordRead])
def get_records_by_uuid_and_bearer_token(request: TestRecordsByUUIDAndBearerToken):

    return TestRecordCRUD.get_records_by_uuid_and_bearer_token(request.agent_id,request.bearer_token)

@router.post("/get_uuid_task_status/{uuid}",status_code=status.HTTP_200_OK,response_model=TestRecordStatus)
def get_uuid_task_status(uuid: str):

    return TestRecordCRUD.get_uuid_task_status(uuid)



@router.post(
    "/search_by_keyword",
    response_model=PaginatedTestRecordResponse,
    status_code=status.HTTP_200_OK,
)
def search_by_keyword(
    payload: dict = Body(..., example={"key_word": "", "page": 1, "page_size": 10})
):
    """
    æŒ‰å…³é”®å­—æœç´¢æµ‹è¯„è®°å½•ï¼š
    - key_word ä¸ºç©ºï¼šè¿”å›å…¨éƒ¨è®°å½•ï¼›
    - key_word ä¸ä¸ºç©ºï¼šåœ¨ task_name æˆ– agent_name ä¸­æ¨¡ç³ŠåŒ¹é…ã€‚
    """

    key_word = payload.get("key_word", "")
    page = payload.get("page", 1)
    page_size = payload.get("page_size", 10)

    if not isinstance(page, int) or not isinstance(page_size, int):
        raise HTTPException(status_code=400, detail="page å’Œ page_size å¿…é¡»ä¸ºæ•´æ•°")

    return TestRecordCRUD.get_records_by_keyword(key_word, page, page_size)

@router.post("/get_parameter_template_by_agent_id",status_code=status.HTTP_200_OK)
def get_parameter_template_by_agent_id(payload: AgentParameterRequest):


    agent_id = payload.agent_id
    dify_api_url = payload.dify_api_url
    bearer_token = payload.bearer_token

    dify_app_url = dify_api_url_2_agent_api_app_url(dify_api_url, agent_id)
    agent_related_info = dify_get_agent_type_and_agent_name(input_agent_manipulate_url=dify_app_url,
                                                            input_bearer_token=bearer_token)
    agent_type = agent_related_info.get("agent_type")
    api_key = ""

    # 5ï¸âƒ£ ç”Ÿæˆ Dify API Key
    try:
        api_key_url = dify_api_url_2_agent_apikey_url(
            dify_api_url, agent_id
        )
        existing_keys = get_dify_agent_api_key(api_key_url, bearer_token)
        if existing_keys:
            api_key = existing_keys[0].get("token")
            logger.debug("âœ… ä½¿ç”¨å·²æœ‰ API Key")
        else:
            created_key = create_dify_agent_api_key(api_key_url, bearer_token)
            api_key = created_key.get("token")
        if not api_key:
            raise ValueError("Dify è¿”å›æ— æ•ˆ API Key")
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆ Dify API Key å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ›å»º Dify API Key å¤±è´¥: {e}")

    excel_buffer = None
    if agent_type == AgentType.WORKFLOW:
        excel_buffer = get_workflow_parameter_template(dify_api_url, api_key)
    elif agent_type == AgentType.CHATFLOW:
        excel_buffer = get_chatflow_parameter_template(dify_api_url, api_key)

    return StreamingResponse(
        excel_buffer,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": 'attachment; filename="parameter_template.xlsx"'}
    )

@router.post("/cancel_test/{uuid_str}")
async def cancel_test(uuid_str: str, db: Session = Depends(get_db)):
    record = TestRecordCRUD.get_by_uuid(db, uuid_str)
    if not record:
        raise HTTPException(status_code=404, detail="Record not found")
    logger.warning(f"å–æ¶ˆè¯·æ±‚å·²æäº¤ï¼Œä»»åŠ¡uuidä¸ºï¼š{uuid_str}")
    TestRecordCRUD.update_by_uuid(db, uuid_str, status=TestStatus.CANCELLED)
    return {"message": "å–æ¶ˆè¯·æ±‚å·²æäº¤ï¼Œä»»åŠ¡å°†åœ¨ä¸‹ä¸€æ¬¡æ£€æµ‹æ—¶ç»ˆæ­¢ âœ…"}

@router.post("/get_datasets_by_agent_and_bearer_paginated", status_code=status.HTTP_200_OK)
def get_datasets_by_agent_and_bearer_paginated(
    payload: dict = Body(..., example={
        "agent_id": "b35f8cb8-0f9a-4e03-87bf-9f090a3fb589",
        "bearer_token": "xxxxx",
        "page": 1,
        "page_size": 10
    })
):
    agent_id = payload.get("agent_id")
    bearer_token = payload.get("bearer_token")
    page = payload.get("page", 1)
    page_size = payload.get("page_size", 10)

    if not agent_id or not bearer_token:
        raise HTTPException(status_code=400, detail="å¿…é¡»æä¾› agent_id å’Œ bearer_token")

    return TestRecordCRUD.get_datasets_by_agent_and_bearer_token(agent_id, bearer_token, page, page_size)

@router.delete("/{uuid_str}/dataset", status_code=status.HTTP_200_OK)
def detach_dataset(uuid_str: str, db: Session = Depends(get_db)):
    """
    åˆ é™¤æŒ‡å®š TestRecord çš„ dataset å¼•ç”¨ï¼ˆä»…ç½®ç©º dataset_uuidï¼Œä¸åˆ é™¤è®°å½•ï¼‰
    """
    record = db.query(TestRecord).filter(
        TestRecord.uuid == uuid_str,
        TestRecord.is_deleted == False
    ).first()

    if not record:
        raise HTTPException(status_code=404, detail="TestRecord not found")

    # å¦‚æœæœ¬èº«å°±æ²¡æœ‰ datasetï¼Œåˆ™æ— éœ€æ“ä½œ
    if record.dataset_uuid is None:
        return {"message": "Already detached", "record": record.to_dict(exclude_none=True)}

    # è°ƒç”¨ CRUD å±‚å‡½æ•°è¿›è¡Œè§£ç»‘
    success = TestRecordCRUD.detach_dataset(uuid_str)

    if not success:
        raise HTTPException(status_code=400, detail="Detach operation failed")

    # é‡æ–°è¯»å–è®°å½•ï¼ˆdataset_uuid å·²ä¸ºç©ºï¼‰
    db.refresh(record)

    return {
        "message": "Dataset detached successfully",
    }

